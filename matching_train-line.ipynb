{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching trains with traffic lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal here is to develop a function that makes it possible to identify the line of a specific delayed train. The reason why we need such a function is because the passenger ridership estimation is given per line where the delay data is per specific train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us import the dataset for all the traffic lines (used in the ridership estimation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import excel file static_pass_all_2024.xlsx\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# read by default 1st sheet of an excel file\n",
    "df_line = pd.read_excel('static_pass_all_2024.xlsx')\n",
    "# drop all the columns except the first 3 (no need for ridership data, only the line number, name and stopping patterns are of interest)\n",
    "df_line = df_line.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now import the train data, more specifically the trains that are affected by delays. Of interest here are particularly Tågnr\tand Tåguppdrag.\n",
    "The goal is to match all of them to a specific line number in df_line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read by default 1st sheet of an excel file\n",
    "df_train = pd.read_excel('metatraindata_2023.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also read the Lupp data where we have more attributes for each train, more particularly the stopping pattern. There are four different files in the data folder named as follows Rapport_T23_vX.csv where X is 11, 19, 28 and 37, we will read all of these and combine them in one dataframe, note the first row of each file is the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define the folder path and file pattern\n",
    "folder_path = 'data/'  # Adjust the folder path if needed\n",
    "file_pattern = 'Rapport_T23_v*.csv'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "file_paths = glob.glob(folder_path + file_pattern)\n",
    "\n",
    "# Read all files into a list of DataFrames\n",
    "dfs = [pd.read_csv(file, header=0) for file in file_paths]\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "df_lupp = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to clean up (make this df a bit smaller), e.g., by removing unnecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from combined_df remove the following columns\n",
    "# År (PAU)\n",
    "# Veckonr (PAU)\n",
    "# Datum (PAU)\n",
    "# Tågslag, but before remove all raws where Tågslag is not RST\n",
    "\n",
    "df_lupp_rst = df_lupp[df_lupp['Tågslag'] == 'RST']\n",
    "df_lupp_rst_clean = df_lupp_rst.drop(columns=['År (PAU)', 'Veckonr (PAU)', 'Datum (PAU)', 'Tågslag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows where both Uppehållstypavgång is Passage and Uppehållstypankomst is Passage\n",
    "df_lupp_rst_clean = df_lupp_rst_clean[(df_lupp_rst_clean['Uppehållstypavgång'] != 'Passage') | (df_lupp_rst_clean['Uppehållstypankomst'] != 'Passage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many trains from df_train that are in df_lupp_rst_clean\n",
    "# for that search using the column Tågnr and Tåguppdrag from df_train\n",
    "# and use similar columns Tåguppdrag and Tågnr from df_lupp_rst_clean\n",
    "# to find the matching trains\n",
    "\n",
    "# make sure these are int in both dataframes\n",
    "df_train['Tågnr'] = df_train['Tågnr'].astype('Int64')\n",
    "df_train['Tåguppdrag'] = df_train['Tåguppdrag'].astype('Int64')\n",
    "df_lupp_rst_clean['Tåguppdrag'] = df_lupp_rst_clean['Tåguppdrag'].astype('Int64')\n",
    "\n",
    "# in df_lupp_rst_clean, remove spaces between numbers first in Tågnr\n",
    "# Remove spaces between numbers in the Tågnr column\n",
    "df_lupp_rst_clean['Tågnr'] = df_lupp_rst_clean['Tågnr'].astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "df_lupp_rst_clean['Tågnr'] = df_lupp_rst_clean['Tågnr'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "3 1\n"
     ]
    }
   ],
   "source": [
    "# for each Tågnr, print how many possible Tåguppdrag there are\n",
    "# this is to see if there are any duplicates in the data\n",
    "x = df_lupp_rst_clean.groupby('Tågnr')['Tåguppdrag'].nunique()\n",
    "y = df_train.groupby('Tågnr')['Tåguppdrag'].nunique()\n",
    "# print the max and min for each dataframe\n",
    "print(x.max(), x.min())\n",
    "print(y.max(), y.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching train delay and Lupp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before trying to find the closest line (line number/name) to a certain train (tågnr/uppdrag). Let us first look att how many delayed trains can we identify in the sample of Lupp data that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching trains: 5833\n",
      "Out of 14474 unique trains\n",
      "Percentage of matching trains: 40.30%\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from df_train and combined_df based on ('Tågnr', 'Tåguppdrag')\n",
    "df_train_test = df_train.drop_duplicates(subset=['Tågnr', 'Tåguppdrag'])\n",
    "combined_df_test = df_lupp_rst_clean.drop_duplicates(subset=['Tågnr', 'Tåguppdrag'])\n",
    "\n",
    "# Perform an inner merge to find matching trains\n",
    "matching_trains = pd.merge(\n",
    "    df_train_test, \n",
    "    combined_df_test, \n",
    "    how='inner', \n",
    "    left_on=['Tågnr', 'Tåguppdrag'], \n",
    "    right_on=['Tågnr', 'Tåguppdrag']\n",
    ")\n",
    "\n",
    "# Count the number of matching trains\n",
    "num_matching_trains = matching_trains.shape[0]\n",
    "print(f\"Number of matching trains: {num_matching_trains}\")\n",
    "\n",
    "# Count the number of unique trains in df_train\n",
    "num_unique_trains = len(df_train_test[['Tåguppdrag']])\n",
    "print(f\"Out of {num_unique_trains} unique trains\")\n",
    "\n",
    "# Calculate the percentage of matching trains\n",
    "matching_percentage = num_matching_trains / num_unique_trains * 100\n",
    "print(f\"Percentage of matching trains: {matching_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that we have stopping pattern information (from Lupp data T23) for around 40% of the delayed trains (in metatraindata_2023). From now on, we focus on matching these 40% delayed trains to their line numbers.\n",
    "\n",
    "First, we append the stopping pattern information to our delayed trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stops = df_lupp_rst_clean[\n",
    "    ((df_lupp_rst_clean['Uppehållstypavgång'].isin(['Uppehåll', 'Första']))) |\n",
    "    ((df_lupp_rst_clean['Uppehållstypankomst'].isin(['Sista'])))\n",
    "]\n",
    "\n",
    "first_dates = filtered_stops.groupby(['Tågnr', 'Tåguppdrag'])['Datum'].min().reset_index()\n",
    "filtered_stops = pd.merge(filtered_stops, first_dates, on=['Tågnr', 'Tåguppdrag', 'Datum'])\n",
    "\n",
    "stops_per_train = (\n",
    "    filtered_stops.groupby(['Tågnr', 'Tåguppdrag'], as_index=False)\n",
    "    .agg({'Delsträckanummer': list, 'Avgångplatssignatur': list, 'Uppehållstypankomst': list, 'AnkomstplatsPlatssignatur': list})\n",
    "    .apply(lambda x: pd.Series({\n",
    "        'Tågnr': x['Tågnr'],\n",
    "        'Tåguppdrag': x['Tåguppdrag'],\n",
    "        'Stopps': (\n",
    "            [stop for i, stop in zip(x['Delsträckanummer'], x['Avgångplatssignatur']) \n",
    "             if pd.notna(stop)] +\n",
    "            [x['AnkomstplatsPlatssignatur'][i] for i, type_a in enumerate(x['Uppehållstypankomst']) \n",
    "             if type_a == 'Sista' and pd.notna(x['AnkomstplatsPlatssignatur'][i])]\n",
    "        )\n",
    "    }), axis=1)\n",
    ")\n",
    "\n",
    "train_stops = pd.merge(\n",
    "    matching_trains, \n",
    "    stops_per_train, \n",
    "    how='inner', \n",
    "    on=['Tågnr', 'Tåguppdrag']\n",
    ")[['Tågnr', 'Tåguppdrag', 'Stopps']]\n",
    "\n",
    "# make sure all the stops are uppercase\n",
    "train_stops['Stopps'] = train_stops['Stopps'].apply(lambda x: [stop.upper() for stop in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbdouAA\\AppData\\Local\\Temp\\ipykernel_19388\\3127480302.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  line_stops = df_line.groupby('Linje').apply(lambda x: list(x['från']) + [x.iloc[-1]['till']]).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Create line_stops by grouping stations ('från' and 'till') for each line ('Linje')\n",
    "line_stops = df_line.groupby('Linje').apply(lambda x: list(x['från']) + [x.iloc[-1]['till']]).reset_index()\n",
    "# Rename columns for clarity\n",
    "line_stops.columns = ['Linje', 'Stopps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching delayed trains to traffic lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the stopping patter for each train (nr+uppdrag), we look at df_line for the closest line with similar stopping patterns.\n",
    "\n",
    "To do that, we can use one of the classification algorithms such as K-Nearest Neighbors (KNN) which we will use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbdouAA\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) ['Abisko östra', 'Algutsgården', 'Almnäs', 'Alvhem', 'Alväng', 'Arlanda norra', 'Arlanda södra', 'Arnäsvall', 'Arvidsjaur', 'Aspedalen', 'Assberg', 'Astrid Lindgrens värld', 'Attarp', 'Avaviken', 'Avesta Centrum', 'Axmarby', 'Barva', 'Basthagen', 'Bastuträsk', 'Bengtsfors', 'Berghem', 'Billingsfors', 'Birsta', 'Bjurhem', 'Bjästa', 'Björketorp', 'Björneborg', 'Björnfjell gränsen', 'Blattnicksele', 'Blomberg', 'Boda', 'Bodens c', 'Borlänge central', 'Borås central', 'Brattby', 'Broddbo', 'Brunna', 'Brännland', 'Brålanda', 'Buresjön', 'Buterud', 'Byvalla', 'Bäckebron', 'Bälgviken', 'Charlottenberg riksgräns', 'Dagarn', 'Dalgränsen', 'Dals Långed', 'Derome', 'Diö Södra', 'Domnarvet', 'Dorotea', 'Dorotea camping', 'Dynäs', 'Edsvalla', 'Ekträsk', 'Enafors', 'Enstaberga', 'Erikstad', 'Eskilstuna c', 'Fagersta c', 'Falkenbergs personstation', 'Falköpings c', 'Falun', 'Farsta strand', 'Fellingsbro', 'Filsbäck', 'Finja', 'Fiskeby', 'Fjällåsen', 'Flädie', 'Folkesta', 'Forsbacka', 'Framnäs city', 'Friluftsgården', 'Frykåsen', 'Frändefors', 'Frånö', 'Furulund', 'Fågelsjö', 'Fåker', 'Gammelstad', 'Garsås', 'Geijersdal', 'Geografiska polcirkeln', 'Getå', 'Gideåbacka', 'Gimonäs', 'Gransjö', 'Granstanda', 'Grohed', 'Grundbro', 'Gräsberg', 'Gullträsk', 'Gussi', 'Gustafs', 'Gäddmyr', 'Gävle c', 'Gålnäs', 'Gårdsjön', 'Göteborgs c', 'Hackås', 'Hagalund', 'Hagge', 'Hallsbergs pbg', 'Halmstads c', 'Hamrångefjärden', 'Harmånger', 'Hasselfors', 'Hasslarp', 'Helsingborg c', 'Helsingborg godsbangård', 'Herrhult', 'Herrljunga central', 'Hillared', 'Hilleby', 'Hillerstorp', 'Hinsnoret', 'Hjulsbro', 'Holmfors', 'Horndals bruk', 'Hoting', 'Hovslätt', 'Hovsta', 'Hussjöby', 'Hyllstofta', 'Häggenås', 'Häggsjön', 'Hällenyland', 'Hälsingenybo', 'Hämrasviken', 'Härad', 'Härnösand', 'Härryda', 'Hästbo', 'Hållsta', 'Håmojåkk', 'Håverud', 'Högbysjön', 'Hölö', 'Hörle', 'Hössjön', 'Isätra', 'Jamtli', 'Jenny', 'Jokkmokk', 'Jonsered Västra', 'Jularbo', 'Jädersbruk', 'Jämtlands Sikås', 'Järlåsa', 'Jönköpings c', 'Jönköpings godsbangård', 'Jönåker', 'Jörn', 'Kaitum', 'Kalix västra', 'Kalmar c', 'Kalmar södra', 'Karlskrona c', 'Karlstads central', 'Karpalund', 'Karsjö', 'Katrineholms c', 'Katterjåkk', 'Kejsarbäcken', 'Kilvo', 'Kiruna malmbangård', 'Kirunavaara', 'Kjula', 'Klenshyttan', 'Knalleland', 'Koler', 'Kolforsen', 'Kolsnäs', 'Kopparåsen', 'Kornsjö  gränsen', 'Korsnäs', 'Korsträsk', 'Koskivaara', 'Kringlan', 'Kristianstads c', 'Kungsgården', 'Kvarnsjö', 'Kvicksund Södra', 'Källene', 'Kåbdalis', 'Könsa', 'Köpmannebro', 'Lakaträsk', 'Lappberg', 'Ledsgård', 'Lene', 'Lidlund', 'Lillhamra', 'Linaälv', 'Linköpings c', 'Liseberg', 'Lit', 'Ljuså', 'Lockarp', 'Lomma', 'Lomselenäs', 'Losesjön', 'Loster', 'Lottefors', 'Lovene', 'Lund c', 'Lycksele', 'Lästringe', 'Låktatjåkka', 'Långbron', 'Långsjön', 'Lödöse södra', 'Lörstrand', 'Maj', 'Malmö Persborg', 'Malmö c', 'Marma norra', 'Marmaverken', 'Medskogsheden', 'Mellby', 'Mellösa', 'Meselefors', 'Mobodarne', 'Mollaryd', 'Mora strand', 'Moskosel', 'Motala', 'Munktorp', 'Myra', 'Månsarp', 'Mölndals nedre', 'Mörtsal', 'Nedansjö', 'Norra Sunderbyn', 'Norra Valbo', 'Norrahammar', 'Norrköpings c', 'Norrsjön', 'Norsesund', 'Nuortikon', 'Nykroppa', 'Nyköping c', 'Nynäshamns centrum', 'Nälden', 'Nässjö c', 'Nättraby', 'Oleby', 'Ombenning', 'Ope', 'Ornäs', 'Orrskog', 'Orsa', 'Oslättfors', 'Ottebol', 'Peberholm', 'Piteälvsbron', 'Polcirkeln', 'Porjus', 'Ralingsås', 'Ramnäs', 'Rautas', 'Rekarne', 'Repbäcken', 'Ripats', 'Rocksjön', 'Rosengård', 'Rundvik', 'Ryggen', 'Ryr', 'Rällså', 'Rämshyttan', 'Råbäck', 'Råskogen', 'Rödberg', 'Röjan', 'Röstbo', 'Saluböle', 'Sandbäck', 'Sandjönäs', 'Sandträsk', 'Sannarp', 'Sellnäs', 'Sikträsk', 'Simeå', 'Skabersjö', 'Skattkärr', 'Skavstaby', 'Skogstorp', 'Skruv', 'Skytts Vemmerlöv', 'Skästra', 'Skåre', 'Skövde c', 'Slagnäs', 'Slätte', 'Snickarbo', 'Snyten', 'Solum', 'Sorsele', 'Spjutsbygd', 'Sprängsviken', 'Stavre', 'Stavreviken', 'Stegsskogen', 'Stjärnhov', 'Stockholm C', 'Stockholm Södra', 'Stockholm city', 'Stora Tuna', 'Stordalen', 'Storflon', 'Storlien gränsen', 'Storträsk', 'Storuman', 'Strångsjö', 'Strömsholm', 'Strömtorp', 'Sundsvall c', 'Sundsvalls Västra', 'Sunnäsbruk', 'Svartvik', 'Svartå', 'Sveg', 'Svenstavik Centrum', 'Sävast', 'Sävastklinten', 'Säve', 'Sävenäs', 'Sågbäcken', 'Söderhamn v', 'Södertälje c', 'Södertälje hamn', 'Södertälje syd undre', 'Södertälje syd övre', 'Sörtjärn', 'Taberg', 'Tallåsen', 'Tandsbyn', 'Tannefors', 'Tisselskog', 'Tjustskolan', 'Tjärnvik', 'Tofta', 'Tomteboda övre', 'Torpåkra', 'Torved', 'Trolmen', 'Trångsviken', 'Trödje', 'Tväråbäck', 'Tystberga', 'Uddevalla c', 'Ulriksfors', 'Ulvshyttan', 'Umeå', 'Umeå godsbangård', 'Uppsala c', 'Uppsala norra', 'Vagnhärad', 'Vallvik', 'Valskog', 'Varjisträsk', 'Vartofta', 'Vassijaure', 'Vattnäs', 'Vedevåg', 'Verkebäck', 'Via', 'Vikmanshyttan', 'Vilhelmina', 'Vilhelmina norra', 'Vilhelmsborg', 'Villersmuren', 'Vojmån', 'Vänersborg c', 'Vännäs norra', 'Väring', 'Värmlands Bro', 'Västerås c', 'Västra Bodarna', 'Västra Torup', 'Västra Ämtervik', 'Vätteryd', 'Ytterhogdal', 'Älvho', 'Älvsbyn', 'Älvsjö godsbangård', 'Äng', 'Ängersjö', 'Äskekärr', 'Åkarp', 'Ålberga', 'Ålsäng', 'Åmyran', 'Ångsågsmossen', 'Ånimskog', 'Årskogen', 'Åryd', 'Åsarna södra', 'Åsbro', 'Åsensbruk', 'Åshammar', 'Öjervik', 'Ökna', 'Ölme', 'Örabäcken', 'Örebro c', 'Örnsköldsviks c', 'Östersunds c', 'Östervärn', 'Överhogdal', 'Överums Bruk'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Tågnr  Tåguppdrag Predicted_Line  \\\n",
      "0       822        5407           5101   \n",
      "1       838        5335           5101   \n",
      "2       862        5317           5101   \n",
      "3       810        5309           5101   \n",
      "4       806        5289           5101   \n",
      "...     ...         ...            ...   \n",
      "5826  11295        1080          10701   \n",
      "5827  13582        1085           5101   \n",
      "5828  32580       15816           5101   \n",
      "5829  29741       29741         10501R   \n",
      "5830  23609        2635           5101   \n",
      "\n",
      "                                            Line_Stopps  \n",
      "0                                  [Stockholms Central]  \n",
      "1                                  [Stockholms Central]  \n",
      "2                                  [Stockholms Central]  \n",
      "3                                  [Stockholms Central]  \n",
      "4                                  [Stockholms Central]  \n",
      "...                                                 ...  \n",
      "5826                   [Malmö central, Svedala, Skurup]  \n",
      "5827                               [Stockholms Central]  \n",
      "5828                               [Stockholms Central]  \n",
      "5829  [Hyllie, Triangeln, Malmö central, Burlöv, Lun...  \n",
      "5830                               [Stockholms Central]  \n",
      "\n",
      "[5831 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Binarize stopping patterns for both lines and trains\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform stopping patterns for lines\n",
    "line_patterns = mlb.fit_transform(line_stops['Stopps'])\n",
    "\n",
    "# Transform stopping patterns for trains using the same binarizer\n",
    "train_patterns = mlb.transform(train_stops['Stopps'])\n",
    "\n",
    "# Assign line IDs as labels\n",
    "line_labels = line_stops['Linje']\n",
    "\n",
    "# Train KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(line_patterns, line_labels)\n",
    "\n",
    "# Predict closest line for each train\n",
    "predicted_lines = knn.predict(train_patterns)\n",
    "\n",
    "# Add predictions and corresponding line stops to the result\n",
    "result = train_stops.copy()\n",
    "result['Predicted_Line'] = predicted_lines\n",
    "\n",
    "# Map the stops from line_stops to the predicted lines\n",
    "line_stops_dict = line_stops.set_index('Linje')['Stopps'].to_dict()\n",
    "result['Line_Stopps'] = result['Predicted_Line'].map(line_stops_dict)\n",
    "\n",
    "# Display the result\n",
    "print(result[['Tågnr', 'Tåguppdrag', 'Predicted_Line', 'Line_Stopps']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
