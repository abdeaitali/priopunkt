{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static train ridership on the Swedish railways 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a static analysis of train ridership on the Swedish railways during 2024!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sampers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings (e.g., from pandas or others)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# File path (assuming the CSV file is named 'Sampers-pax-2018-cleaned.csv')\n",
    "file_path_sampers = os.path.join(current_directory, 'data', 'Sampers-pax-2024-cleaned.csv')\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_pax = pd.read_csv(file_path_sampers, sep=';', low_memory=False, dtype={\"line\": str})  # Force 'line' column as string\n",
    "\n",
    "# Define a function to replace commas with dots and remove hidden characters\n",
    "def clean_column_values(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(',', '.')  # Replace commas with dots for decimals\n",
    "        value = value.replace('\\r', '').replace('\\n', '')  # Remove carriage returns and line breaks\n",
    "    return value\n",
    "\n",
    "# Apply cleaning to all columns\n",
    "for column in df_pax.columns:\n",
    "    if df_pax[column].dtype == 'object':\n",
    "        df_pax[column] = df_pax[column].apply(clean_column_values)\n",
    "\n",
    "# Convert all columns except the first three to numeric\n",
    "numeric_columns = df_pax.columns[2:]  # Select all columns starting from the 3th (index 2)\n",
    "df_pax[numeric_columns] = df_pax[numeric_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passengers ombord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new data structure where the number of passengers ombord is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns for boardings and alightings\n",
    "boarding_cols = [\"Nat pr PÅ\", \"Nat tj PÅ\", \"Nat arb PÅ\", \"Reg arb PÅ\", \"Reg tj PÅ\", \"Reg övr PÅ\"]\n",
    "alighting_cols = [\"Nat pr AV\", \"Nat tj AV\", \"Nat arb AV\", \"Reg arb AV\", \"Reg tj AV\", \"Reg övr AV\"]\n",
    "\n",
    "# Ensure the relevant columns are floats\n",
    "df_pax[boarding_cols] = df_pax[boarding_cols].astype(float)\n",
    "df_pax[alighting_cols] = df_pax[alighting_cols].astype(float)\n",
    "\n",
    "# Shift the values of alighting columns by one row within each group and replace missing values with zeros\n",
    "df_pax[alighting_cols] = df_pax.groupby('line')[alighting_cols].shift(+1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each line, compare the total number of boardings and alightings\n",
    "# if the total number of boardings is greater than the total number of alightings, print the line\n",
    "for line in df_pax['line'].unique():\n",
    "    df_line = df_pax[df_pax['line'] == line]\n",
    "    total_boardings = df_line[boarding_cols].sum().sum()\n",
    "    total_alightings = df_line[alighting_cols].sum().sum()\n",
    "    if total_boardings > total_alightings + 1e-3:\n",
    "        print(f\"Line {line} has more boardings ({total_boardings}) than alightings ({total_alightings})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for non-zero boardings and alightings\n",
    "has_boardings = df_pax[boarding_cols].sum(axis=1) > 0\n",
    "has_alightings = df_pax[alighting_cols].sum(axis=1) > 0\n",
    "\n",
    "# Keep rows where either boardings or alightings occur\n",
    "df_pax = df_pax[has_boardings | has_alightings].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "data = []\n",
    "\n",
    "# Group by 'line' and process each group separately\n",
    "for line, group in df_pax.groupby(\"line\"):\n",
    "    # Reset the index for each group to ensure sequential processing\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    # Initialize onboard counters for each category of passengers\n",
    "    onboard = {col: 0 for col in boarding_cols}\n",
    "\n",
    "    for i in range(len(group) - 1):\n",
    "        # Add boardings at the current station\n",
    "        for col in boarding_cols:\n",
    "            onboard[col] += group.loc[i, col]\n",
    "\n",
    "        # Round and ensure counts are >= 0\n",
    "        #rounded_onboard = {k: max(round(v), 0) for k, v in onboard.items()}\n",
    "        # Without rounding nor ensuring counts are >= 0\n",
    "        rounded_onboard = onboard\n",
    "\n",
    "        # Subtract alightings for the current station (these apply to the next segment)\n",
    "        for b_col, a_col in zip(boarding_cols, alighting_cols):\n",
    "            onboard[b_col] -= group.loc[i, a_col]\n",
    "\n",
    "        # Append the data for the current segment (from the current station to the next)\n",
    "        data.append({\n",
    "            \"Linje\": line,\n",
    "            # the first and last station of the line\n",
    "            \"först\": group.loc[0, \"Station\"],\n",
    "            \"sist\": group.iloc[-1][\"Station\"],\n",
    "            # the pair of stations for the current segment\n",
    "            \"från\": group.loc[i, \"Station\"],\n",
    "            \"till\": group.loc[i + 1, \"Station\"],\n",
    "            # the number of passengers onboard for the current segment\n",
    "            \"ombord_pr_nat\": rounded_onboard[\"Nat pr PÅ\"],\n",
    "            \"ombord_tj_nat\": rounded_onboard[\"Nat tj PÅ\"],\n",
    "            \"ombord_arb_nat\": rounded_onboard[\"Nat arb PÅ\"],\n",
    "            \"ombord_arb_reg\": rounded_onboard[\"Reg arb PÅ\"],\n",
    "            \"ombord_tj_reg\": rounded_onboard[\"Reg tj PÅ\"],\n",
    "            \"ombord_övr_reg\": rounded_onboard[\"Reg övr PÅ\"],\n",
    "            # the number of passengers alighting at the next station\n",
    "            \"avstigande_pr_nat\": group.loc[i+1, \"Nat pr AV\"],\n",
    "            \"avstigande_tj_nat\": group.loc[i+1, \"Nat tj AV\"],\n",
    "            \"avstigande_arb_nat\": group.loc[i+1, \"Nat arb AV\"],\n",
    "            \"avstigande_arb_reg\": group.loc[i+1, \"Reg arb AV\"],\n",
    "            \"avstigande_tj_reg\": group.loc[i+1, \"Reg tj AV\"],\n",
    "            \"avstigande_övr_reg\": group.loc[i+1, \"Reg övr AV\"],\n",
    "            # the number of passengers boarding at the current station\n",
    "            \"påstigande_pr_nat\": group.loc[i, \"Nat pr PÅ\"],\n",
    "            \"påstigande_tj_nat\": group.loc[i, \"Nat tj PÅ\"],\n",
    "            \"påstigande_arb_nat\": group.loc[i, \"Nat arb PÅ\"],\n",
    "            \"påstigande_arb_reg\": group.loc[i, \"Reg arb PÅ\"],\n",
    "            \"påstigande_tj_reg\": group.loc[i, \"Reg tj PÅ\"],\n",
    "            \"påstigande_övr_reg\": group.loc[i, \"Reg övr PÅ\"]\n",
    "        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "new_df_pax = pd.DataFrame(data)\n",
    "\n",
    "# Filter out rows where the station name is \"0\" or \"A6\"\n",
    "#new_df_pax = new_df_pax[(new_df_pax[\"från\"] != \"0\") | (new_df_pax[\"från\"] != \"A6\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if either från or till is \"0\" or \"A6\"\n",
    "# if so, print the rows\n",
    "for i in range(len(new_df_pax)):\n",
    "    if new_df_pax.loc[i, \"från\"] == \"0\" or new_df_pax.loc[i, \"från\"] == \"A6\":\n",
    "        print(new_df_pax.loc[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows with the same line number have the same först and sist.\n",
    "# check if först and sist are the same for each line number\n",
    "for line in new_df_pax[\"Linje\"].unique():\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line][\"först\"].nunique() != 1:\n",
    "        print(line)\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line][\"sist\"].nunique() != 1:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each line number, check if there is an inverse line number, i.e., in the format \"line number\" + \"R\"\n",
    "for line in new_df_pax[\"Linje\"].unique():\n",
    "    if line[-1] == \"R\":\n",
    "        if line[:-1] not in new_df_pax[\"Linje\"].unique():\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the pair (först, sist) is the same for a line and its inverse line\n",
    "for line in new_df_pax[\"Linje\"].unique():\n",
    "    if line[-1] == \"R\":\n",
    "        if new_df_pax[new_df_pax[\"Linje\"] == line][\"först\"].nunique() != 1:\n",
    "            print(line)\n",
    "        if new_df_pax[new_df_pax[\"Linje\"] == line][\"sist\"].nunique() != 1:\n",
    "            print(line)\n",
    "    else:\n",
    "        if line + \"R\" not in new_df_pax[\"Linje\"].unique():\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the following validation, the lines 10002 and 10502 were found to be peculiar so a manual modification was made. Decided to drop these lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n",
      "10502\n"
     ]
    }
   ],
   "source": [
    "# each line and its inverse has only one pair (först, sist)\n",
    "# compare the unique pairs (först, sist) for each line and its inverse\n",
    "for line in new_df_pax[\"Linje\"].unique():\n",
    "    if line[-1] == \"R\":\n",
    "        continue\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line][\"först\"].nunique() != 1:\n",
    "        print(line)\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line][\"sist\"].nunique() != 1:\n",
    "        print(line)\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line + \"R\"][\"först\"].nunique() != 1:\n",
    "        print(line + \"R\")\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line + \"R\"][\"sist\"].nunique() != 1:\n",
    "        print(line + \"R\")\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line][\"först\"].unique() != new_df_pax[new_df_pax[\"Linje\"] == line + \"R\"][\"sist\"].unique():\n",
    "        print(line)\n",
    "    if new_df_pax[new_df_pax[\"Linje\"] == line][\"sist\"].unique() != new_df_pax[new_df_pax[\"Linje\"] == line + \"R\"][\"först\"].unique():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop lines 10002 and 10502 and their inverse\n",
    "new_df_pax = new_df_pax[(new_df_pax[\"Linje\"] != \"10002\") & (new_df_pax[\"Linje\"] != \"10002R\") & (new_df_pax[\"Linje\"] != \"10502\") & (new_df_pax[\"Linje\"] != \"10502R\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each line, check if the number of boardings is the same as the number of alightings\n",
    "for line in new_df_pax[\"Linje\"].unique():\n",
    "    if abs(new_df_pax[new_df_pax[\"Linje\"] == line][[\"påstigande_pr_nat\", \"påstigande_tj_nat\", \"påstigande_arb_nat\", \"påstigande_arb_reg\", \"påstigande_tj_reg\", \"påstigande_övr_reg\"]].sum().sum() - new_df_pax[new_df_pax[\"Linje\"] == line][[\"avstigande_pr_nat\", \"avstigande_tj_nat\", \"avstigande_arb_nat\", \"avstigande_arb_reg\", \"avstigande_tj_reg\", \"avstigande_övr_reg\"]].sum().sum())>1e-3:\n",
    "        print(line)\n",
    "        # print the number of boardings and alightings for each line\n",
    "        print(new_df_pax[new_df_pax[\"Linje\"] == line][[\"påstigande_pr_nat\", \"påstigande_tj_nat\", \"påstigande_arb_nat\", \"påstigande_arb_reg\", \"påstigande_tj_reg\", \"påstigande_övr_reg\"]].sum().sum())\n",
    "        print(new_df_pax[new_df_pax[\"Linje\"] == line][[\"avstigande_pr_nat\", \"avstigande_tj_nat\", \"avstigande_arb_nat\", \"avstigande_arb_reg\", \"avstigande_tj_reg\", \"avstigande_övr_reg\"]].sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first plot the ridership (pax ombord) for some random southbound lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'line' column is treated as text (string type)\n",
    "new_df_pax['Linje'] = new_df_pax['Linje'].astype(str)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "output_filename = \"static_pass_all_2024.xlsx\"\n",
    "new_df_pax.to_excel(output_filename, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
