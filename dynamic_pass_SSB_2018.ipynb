{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic train ridership on the Swedish Southern Main Line 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting the static ridership from sampers, this is the estimation of the dynamic train ridership on the Southern Main Line during 2018!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first read the existing relevant data, namely:\n",
    "- Static ridership (from Sampers), i.e., the average number of passengers onboard between each consecutive links per line and weekday.\n",
    "- Lines, including the first and last station, the average number of turer (round-trips) during a weekday. Note that there are lines with the same start and last station but they are two different lines as they have different stops.\n",
    "- Needed later is the Traffic data (from Lupp), we are more interested here in the scheduled number of trains during (off)peak hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings (e.g., from pandas or others)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define file paths (assuming the files are in a 'data' subdirectory)\n",
    "file_path_lines = os.path.join(current_directory, 'data', 'Linjer_sträckor_turer.xlsx')\n",
    "file_path_stations = os.path.join(current_directory, 'Plats_sign_pos.xlsx')\n",
    "file_path_static_pass = os.path.join(current_directory, 'static_pass_SSB_2018.xlsx')\n",
    "\n",
    "\n",
    "# Define a function to replace commas with dots and remove hidden characters\n",
    "def clean_column_values(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(',', '.')  # Replace commas with dots for decimals\n",
    "        value = value.replace('\\r', '').replace('\\n', '')  # Remove carriage returns and line breaks\n",
    "    return value\n",
    "\n",
    "# Read the additional Excel files into DataFrames\n",
    "df_lines = pd.read_excel(file_path_lines, dtype={\"line\": str})  # Read lines data\n",
    "df_stations = pd.read_excel(file_path_stations, dtype={\"station\": str})  # Read station positions data\n",
    "df_static_pass = pd.read_excel(file_path_static_pass, dtype={\"line\": str})  # Read static ridership data\n",
    "\n",
    "# Clean all string columns in the new DataFrames\n",
    "df_lines = df_lines.applymap(lambda x: clean_column_values(x) if isinstance(x, str) else x)\n",
    "df_stations = df_stations.applymap(lambda x: clean_column_values(x) if isinstance(x, str) else x)\n",
    "df_static_pass = df_static_pass.applymap(lambda x: clean_column_values(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of collected data (columns, types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lines DataFrame Column Types:\n",
      "Linje                    object\n",
      "Sträcka                  object\n",
      "Vehicle type              int64\n",
      "Mode                     object\n",
      "Antal dubbel-turer        int64\n",
      "Linjetid minuter        float64\n",
      "Linjelängd kilometer    float64\n",
      "dtype: object\n",
      "\n",
      "Stations DataFrame Column Types:\n",
      "Plats        object\n",
      "Signatur     object\n",
      "Latitud     float64\n",
      "Longitud    float64\n",
      "dtype: object\n",
      "\n",
      "Static Passenger DataFrame Column Types:\n",
      "line                          object\n",
      "From                          object\n",
      "To                            object\n",
      "Nat_Priv_Ombord                int64\n",
      "Nat_Tj_Ombord                  int64\n",
      "Reg_arb_Ombord                 int64\n",
      "Reg_tj_Ombord                  int64\n",
      "Reg_övr_Ombord                 int64\n",
      "Nationella_tot_Ombord          int64\n",
      "Regionala_tot_Ombord           int64\n",
      "Tot_Ombord                     int64\n",
      "Nat_Priv_Påstigande          float64\n",
      "Nat_Tj_Påstigande            float64\n",
      "Reg_arb_Påstigande           float64\n",
      "Reg_tj_Påstigande            float64\n",
      "Reg_övr_Påstigande           float64\n",
      "Nationella_tot_Påstigande    float64\n",
      "Regionala_tot_Påstigande     float64\n",
      "Totalt Påstigande            float64\n",
      "Nat_Priv_Avstigande          float64\n",
      "Nat_Tj_Avstigande            float64\n",
      "Reg_arb_Avstigande           float64\n",
      "Reg_tj_Avstigande            float64\n",
      "Reg_övr_Avstigande           float64\n",
      "Nationella_tot_Avstigande    float64\n",
      "Regionala_tot_Avstigande     float64\n",
      "Tot_Avstigande               float64\n",
      "Direction                     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print DataFrame summaries for verification\n",
    "print(\"\\nLines DataFrame Column Types:\")\n",
    "print(df_lines.dtypes)\n",
    "\n",
    "print(\"\\nStations DataFrame Column Types:\")\n",
    "print(df_stations.dtypes)\n",
    "\n",
    "print(\"\\nStatic Passenger DataFrame Column Types:\")\n",
    "print(df_static_pass.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the lines where the corresponding trains are passing by at least two consecutive stations of the southern main line (SSB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_pax is the DataFrame you are working with\n",
    "\n",
    "# List of ordered stations on the Southern Main Line (SSB)\n",
    "stations_SSB_ordered_north_to_south = [\n",
    "    \"Stockholms Central\", \"Stockholms Södra\", \"Årstaberg\", \"Älvsjö\", \"Stuvsta\",\n",
    "    \"Huddinge\", \"Flemingsberg\", \"Björnkulla\", \"Malmsjö\", \"Södertälje syd övre\",\n",
    "    \"Bränninge\", \"Järna\", \"Mölnbo\", \"Gnesta\", \"Kolke\", \"Björnlunda\", \"Stjärnhov\",\n",
    "    \"Nyckelsjön\", \"Sparreholm\", \"Skebokvarn\", \"Flen\", \"Sköldinge\", \"Stolpstugan\",\n",
    "    \"Katrineholms central\", \"Strångsjö\", \"Simonstorp\", \"Åby\", \"Norrköpings central\",\n",
    "    \"Fiskeby\", \"Kimstad\", \"Norsholm\", \"Gistad\", \"Linghem\", \"Linköpings central\",\n",
    "    \"Vikingstad\", \"Mantorp\", \"Mjölby\", \"Lindekullen\", \"Boxholm\", \"Sommen\",\n",
    "    \"Tranås\", \"Gripenberg\", \"Frinnaryd\", \"Ralingsås\", \"Aneby\", \"Flisby\", \"Vimnarp\",\n",
    "    \"Gamlarp\", \"Nässjö central\", \"Grimstorp\", \"Bodafors\", \"Ulvstorp\", \"Sävsjö\",\n",
    "    \"Aleholm\", \"Stockaryd\", \"Rörvik\", \"Lammhult\", \"Grevaryd\", \"Lidnäs\", \"Moheda\",\n",
    "    \"Gåvetorp\", \"Alvesta\", \"Blädinge\", \"Vislanda\", \"Eneryda\", \"Diö Norra\", \"Diö Södra\",\n",
    "    \"Älmhult\", \"Killeberg\", \"Tunneby\", \"Osby\", \"Hästveda\", \"Mosselund\", \"Ballingslöv\",\n",
    "    \"Hässleholm\", \"Mellby\", \"Sösdala\", \"Vätteryd\", \"Tjörnarp\", \"Höör\", \"Stehag\", \"Eslöv\",\n",
    "    \"Dammstorp\", \"Örtofta\", \"Stångby\", \"Tornhill\", \"Lunds central\", \"Klostergården\",\n",
    "    \"Flackarp\", \"Hjärup\", \"Åkarps norra\", \"Åkarp\", \"Burlöv\", \"Arlöv\", \"Malmö godsbangård\",\n",
    "    \"Malmö central\"\n",
    "]\n",
    "\n",
    "# Function to check if a train passes at least two distinct stations in the SSB\n",
    "def passes_two_or_more_stations_for_line(line_df):\n",
    "    # Check if the line passes through at least two distinct SSB stations\n",
    "    station_indices = set()  # Use a set to keep track of unique station indices\n",
    "\n",
    "    for _, row in line_df.iterrows():\n",
    "        from_station = row['From']\n",
    "        to_station = row['To']\n",
    "\n",
    "        if from_station in stations_SSB_ordered_north_to_south:\n",
    "            station_indices.add(stations_SSB_ordered_north_to_south.index(from_station))\n",
    "        if to_station in stations_SSB_ordered_north_to_south:\n",
    "            station_indices.add(stations_SSB_ordered_north_to_south.index(to_station))\n",
    "\n",
    "    # If the line passes through at least two distinct stations, we return True\n",
    "    return len(station_indices) >= 2\n",
    "\n",
    "# Group the DataFrame by 'line' to analyze each line individually\n",
    "lines_meeting_criteria = []\n",
    "for line, line_df in df_pax.groupby('line'):\n",
    "    if passes_two_or_more_stations_for_line(line_df):\n",
    "        lines_meeting_criteria.append(line)\n",
    "\n",
    "# Filter the original DataFrame to include all rows for the lines that meet the criteria\n",
    "filtered_df_pax = df_pax[df_pax['line'].isin(lines_meeting_criteria)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all the pairs not on the southern main line SSB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first plot the ridership (pax ombord) for some random southbound lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['line', 'From', 'To', 'Nat_Priv_Ombord', 'Nat_Tj_Ombord',\n",
       "       'Reg_arb_Ombord', 'Reg_tj_Ombord', 'Reg_övr_Ombord',\n",
       "       'Nationella_tot_Ombord', 'Regionala_tot_Ombord', 'Tot_Ombord',\n",
       "       'Nat_Priv_Påstigande', 'Nat_Tj_Påstigande', 'Reg_arb_Påstigande',\n",
       "       'Reg_tj_Påstigande', 'Reg_övr_Påstigande', 'Nationella_tot_Påstigande',\n",
       "       'Regionala_tot_Påstigande', 'Totalt Påstigande', 'Nat_Priv_Avstigande',\n",
       "       'Nat_Tj_Avstigande', 'Reg_arb_Avstigande', 'Reg_tj_Avstigande',\n",
       "       'Reg_övr_Avstigande', 'Nationella_tot_Avstigande',\n",
       "       'Regionala_tot_Avstigande', 'Tot_Avstigande', 'Direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_pax.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to static_pass_SSB_2018.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'line' column is treated as text (string type)\n",
    "filtered_df_pax['line'] = filtered_df_pax['line'].astype(str)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "output_filename = \"static_pass_SSB_2018.xlsx\"\n",
    "filtered_df_pax.to_excel(output_filename, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
